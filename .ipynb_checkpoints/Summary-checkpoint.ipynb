{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASETS\n",
    "\n",
    "1. NinaPro5 http://ninaweb.hevs.ch/\n",
    "2. CoteAllard https://github.com/UlysseCoteAllard/MyoArmbandDataset\n",
    "3. EPN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Learning (Few samples + prior knowledge)\n",
    "\n",
    "\n",
    "## LDA Classifier\n",
    "$$\\arg\\max_{c} (g(x)_c=\\mu_c^T \\Sigma^{-1}x-\\frac{1}{2}\\mu_c^T \\Sigma^{-1} \\mu_c^T + \\ln p(w_c))$$\n",
    "\n",
    "where $\\mu_c$ is the mean vector of the training samples of class $c$, and $p(Ï‰_c)$ is the prior probability of class $c$. $\\Sigma$ is the pooled sample covariance matrix.\n",
    "\n",
    "## Algorithms\n",
    "\n",
    "### Liu:\n",
    "\n",
    "Suppose there have been $P$ pre-trained models stored in memory, which are trained on data acquired from p prior days. These models can be represented tegrate these prior models into the training process due to their consistence with the current data to some extent. The framework as ($\\hat{\\mu}_c$, $\\hat{\\Sigma}_c$), such that $c=1:C$, $k=1:P$). In the new day, we can integrate these prior models into the training process due to their consistence with the current data to some extent. The framework of such integration method is formulated as:\n",
    "\n",
    "$$\\mu_c=(1-r)\\bar{\\mu}_c + r \\sum_{k=1}^{P}w_c^k \\hat{\\mu}_c^k$$\n",
    "\n",
    "$$\\Sigma_c=(1-r)\\bar{\\Sigma}_c + r \\sum_{k=1}^{P}w_c^k \\hat{\\Sigma}_c^k$$\n",
    "\n",
    "where $\\bar{\\mu}_c$ and $\\bar{\\Sigma}_c$ are the mean vector and covariance matrix of class $c$ estimated on the incoming training samples of the current day; $w_c^k$ is the weight determining how much the model\n",
    "of kth day can be reused for class $c$. We see that the anticipated model is the combination of the current model and the weighted sum of prior models through a tradeoff parameter $r$, which is set based on empirical experiments.\n",
    "\n",
    "\n",
    "$$r=0.5$$\n",
    "\n",
    "$$w_c^k=\\frac{\\frac{1}{D(\\bar{\\mu}_c,\\hat{\\mu}_c^k,\\hat{\\Sigma}_c^k)}}{\\sum_{k=1}^{P}\\frac{1}{D(\\bar{\\mu}_c,\\hat{\\mu}_c^k,\\hat{\\Sigma}_c^k)}}$$\n",
    "\n",
    "where $D$ is the Mahalanobis distance.\n",
    "\n",
    "### Proposed algorithm:\n",
    "\n",
    "$$\\mu_c=\\frac{1}{P} \\sum_{k=1}^{P} ((1-r_c^k) \\bar{\\mu}_c  + r_c^k \\hat{\\mu}_c^k )$$\n",
    "\n",
    "$$\\Sigma_c=\\frac{1}{P} \\sum_{k=1}^{P} ((1-r_c^k) \\bar{\\Sigma}_c  + r_c^k \\hat{\\Sigma}_c^k )$$\n",
    "\n",
    "$$r_c^k=\\frac{F1_c^k}{\\bar{F1}_c + F1_c^k}$$\n",
    "\n",
    "where $\\bar{F1}_c$ is the $F_{score}$ of class $c$, using the LDA model $M_c (\\bar{\\mu}_c, \\bar{\\Sigma}_c)$, and $F1_c^k$ is the $F_{score}$ of class $c$, using the LDA model $M_c^k (\\hat{\\mu}_c^k, \\hat{\\Sigma}_c^k)$, which are estimated on the incoming training samples of the current day.\n",
    "\n",
    "$$F_{score} =2\\frac{precision*recall}{precision+recall}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS DATASETS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
